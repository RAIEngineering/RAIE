---
layout: page
title: RAIE 2023
---

<!-- <p><img src="/img/pierrebourque.jpg" width="200" /><a href="https://profs.etsmtl.ca/pbourque">Pierre Bourque</a> - ing., Ph.D.</p> -->

***2nd International Workshop on Responsible AI Engineering (RAIE'23)***

<!-- Co-located with [**ICSE 2022**](https://conf.researchr.org/home/icse-2022)
<br>
Virtual
<br>
May 21-29, 2022 -->

### Theme & Goals

Artificial intelligence (AI) has the potential to tackle grand societal and environmental challenges, increase productivity, transform industries and provide comprehensive intelligent services to communities and societies. The global AI market was valued at USD 387.45 billion in 2022 and is expected to grow to $1,394.30 billion by 2029, with an annual growth rate of 20.1%. For the world to realise these benefits however, it will be important to ensure the AI systems developed and deployed by business, governments and academia are trustworthy throughout their entire lifecycle and trusted by citizens who are expected to use them and rely on them. To achieve this, the development and use of AI systems must align with ethical and legal standards. This concern has triggered significant national interest to pursue and realize trustworthy and responsible AI around the world.

A number of AI ethics principles have been published recently, which AI systems should conform to. Some consensus around AI ethics principles has begun to emerge. A principle-based approach allows technology-neutral, future-proof and context-specific interpretations and operationalization. However, high-level AI ethics principles are far from ensuring trustworthy and responsible AI systems. There is a significant gap between high-level AI ethics principles and low-level concrete practice for practitioners. Without further concrete methods and tools, practitioners are left with nothing much beyond truisms. For example, it is a very challenging and complex task to operationalize the human-centered value principle regarding how it can be designed for, implemented and monitored throughout the entire lifecycle of AI systems. Trustworthy and responsible AI challenges can occur at any stage of the AI system development lifecycle, crosscutting AI components, non-AI components, and data components of systems. New and improved software engineering approaches are required to ensure that the AI systems developed are trustworthy throughout the entire lifecycle and trusted by those who use and rely on them.

The goal of this workshop is to bring together researchers and practitioners in software engineering and AI to build up a community that will target the software engineering challenges that developers and technologists are facing in developing AI systems responsibly. 

### Topics of Interest

In this workshop, we are looking for cutting-edge software engineering methods, techniques, tools and real-world case studies that can help operationalize responsible AI.

Topics of interests include, but are not limited to:

- Requirement engineering for responsible AI
- Software architecture and design of responsible AI systems
- Verification and validation for responsible AI systems
- DevOps, AIOps, MLOps for responsible AI systems
- Development processes for responsible AI systems
- Responsible AI governance
- Explainable AI engineering
- Reproducibility and traceability of AI systems
- Trust and trustworthiness of AI systems
- Human-centric AI systems and human values in AI systems


**Two types of contributions will be considered:**

1. A research or experience full paper with 8 pages max. Papers describing the challenges, starting results, vision papers, or the experience papers from or in cooperation with the practitioners are encouraged.

2. A short research or experience paper with 4 pages max. The same topics as for long papers.
<!-- 
**Selected papers presented at the workshop will be invited to consider submission (after significant extension) for the IEEE flagship magazine - [IEEE Computer special issue on software engineering for responsible AI](https://www.computer.org/digital-library/magazines/co/call-for-papers-special-issue-on-software-engineering-for-responsible-ai)** -->

### Submission Guidelines
TBA
<!-- • Submissions must conform to the [ACM conference paper formatting instructions](https://www.acm.org/publications/proceedings-template). The official publication date of the workshop proceedings is the date the proceedings are made available in the ACM Library. This date may be up to two weeks prior to the first day of ICSE 2022. The official publication date affects the deadline for any patent filings related to published work.

• LaTeX users must use the provided acmart.cls and ACM-Reference-Format.bst without modification, enable the conference format in the preamble of the document (i.e., {\documentclass[sigconf,review]{acmart}), and use the ACM reference format for the bibliography (i.e., \bibliographystyle{ACM-Reference-Format}). The review option adds line numbers, thereby allowing referees to refer to specific lines in their comments.

• All submitted papers will be reviewed on the basis of technical quality, relevance, significance, and clarity by the program committee. Please note, the submissions should NOT be double blind, i.e. in the submission the authors should be specified. All workshop papers should be submitted electronically in PDF format through the [EasyChair workshop website](https://easychair.org/conferences/?conf=se4rai22).

• All submissions must be in PDF. -->


### Important Dates

**Submission Deadline:** July 10, 2023
<br>
**Notification of Acceptance:** August 10, 2023
<br>
**Camera Ready (Hard):** August 24, 2023

### Organizing Committee

#### Workshop Organisers

• Qinghua Lu, CSIRO, Australia, <qinghua.lu@data61.csiro.au>

• TBA

#### Program Committee

• TBA
<!-- Ipek Ozkaya, Carnegie Mellon University, Software Engineering Institute, US

• Jan Bosch, Chalmers University of Technology, Sweden

• David Lo, Singapore Management University, Singapore

• Ian Gorton, Northeastern University, US

• Ivica Crnkovic, Chalmers University of Technology, Sweden

• Jinqiu Yang, Concordia University, Canada

• Foutse Khomh, DGIGL, Ecole Polytechnique de Montréal, Canada

• Chakkrit Tantithamthavorn, Monash University, Australia

• Karthik Vaidhyanathan, University of L'Aquila, Italy

• Carol Smith, Carnegie Mellon University, Software Engineering Institute, US

• Michael Felderer, University of Innsbruck, Austria

• Jan S. Rellermeyer, Delft University of Technology, Netherlands

• Tommi Mikkonen, University of Helsinki, Finland

• Henry Muccini, University of L'Aquila, Italy

• Emad Shihab, Concordia University, Canada

• Eric Knauss, University of Gothenburg, Sweden

• Markus Borg, RISE Research Instititutes of Sweden, Sweden -->
