---
layout: page
title: RAIE 2023
---

<!-- <p><img src="/img/pierrebourque.jpg" width="200" /><a href="https://profs.etsmtl.ca/pbourque">Pierre Bourque</a> - ing., Ph.D.</p> -->

## 2nd International Workshop on Responsible AI Engineering (RAIE'23)

<!-- Co-located with [**ICSE 2022**](https://conf.researchr.org/home/icse-2022)
<br>
Virtual
<br>
May 21-29, 2022 -->

### Theme & Goals

Artificial intelligence (AI) has the potential to tackle grand societal and environmental challenges, increase productivity, transform industries and provide comprehensive intelligent services to communities and societies. The global AI market was valued at USD 387.45 billion in 2022 and is expected to grow to $1,394.30 billion by 2029, with an annual growth rate of 20.1%. For the world to realise these benefits however, it will be important to ensure the AI systems developed and deployed by business, governments and academia are trustworthy throughout their entire lifecycle and trusted by citizens who are expected to use them and rely on them. To achieve this, the development and use of AI systems must align with ethical and legal standards. This concern has triggered significant national interest to pursue and realize trustworthy and responsible AI around the world.

A number of AI ethics principles have been published recently, which AI systems should conform to. Some consensus around AI ethics principles has begun to emerge. A principle-based approach allows technology-neutral, future-proof and context-specific interpretations and operationalization. However, high-level AI ethics principles are far from ensuring trustworthy and responsible AI systems. There is a significant gap between high-level AI ethics principles and low-level concrete practice for practitioners. Without further concrete methods and tools, practitioners are left with nothing much beyond truisms. For example, it is a very challenging and complex task to operationalize the human-centered value principle regarding how it can be designed for, implemented and monitored throughout the entire lifecycle of AI systems. Trustworthy and responsible AI challenges can occur at any stage of the AI system development lifecycle, crosscutting AI components, non-AI components, and data components of systems. New and improved software engineering approaches are required to ensure that the AI systems developed are trustworthy throughout the entire lifecycle and trusted by those who use and rely on them.

The goal of this workshop is to bring together researchers and practitioners in software engineering and AI to build up a community that will target the software engineering challenges that developers and technologists are facing in developing AI systems responsibly. 

### Topics of Interest

In this workshop, we are looking for cutting-edge software engineering methods, techniques, tools and real-world case studies that can help operationalize responsible AI.

Topics of interests include, but are not limited to:

- Requirement engineering for responsible AI
- Software architecture and design of responsible AI systems
- Verification and validation for responsible AI systems
- DevOps, AIOps, MLOps for responsible AI systems
- Development processes for responsible AI systems
- Responsible AI governance
- Explainable AI engineering
- Reproducibility and traceability of AI systems
- Trust and trustworthiness of AI systems
- Human-centric AI systems and human values in AI systems


**Two types of contributions will be considered:**

1. A research or experience full paper with 8 pages max. Papers describing the challenges, starting results, vision papers, or the experience papers from or in cooperation with the practitioners are encouraged.

2. A short research or experience paper with 4 pages max. The same topics as for long papers.


### Submission Guidelines
TBA


### Important Dates

**Submission Deadline:** July 10, 2023
<br>
**Notification of Acceptance:** August 10, 2023
<br>
**Camera Ready (Hard):** August 24, 2023

### Organizing Committee

#### Workshop Organisers

• Qinghua Lu, CSIRO, Australia, <qinghua.lu@data61.csiro.au>

• TBA

#### Program Committee

• TBA
